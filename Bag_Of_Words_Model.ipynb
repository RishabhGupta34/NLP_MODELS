{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bag_Of_Words_Model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RishabhGupta34/NLP_MODELS/blob/master/Bag_Of_Words_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8mO0xr0-4aF5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F7ztxXJr4L0u",
        "colab_type": "code",
        "outputId": "b37135f0-9fd0-4150-c0c6-3cf451eeb37b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"your_username\",\"key\":\"your_key\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!chmod 600 /content/.kaggle/kaggle.json\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!kaggle competitions download -c word2vec-nlp-tutorial"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n",
            "mkdir: cannot create directory ‘.kaggle’: File exists\n",
            "- path is now set to: {/content}\n",
            "Downloading sampleSubmission.csv to {/content}/competitions/word2vec-nlp-tutorial\n",
            "  0% 0.00/276k [00:00<?, ?B/s]\n",
            "100% 276k/276k [00:00<00:00, 85.2MB/s]\n",
            "Downloading unlabeledTrainData.tsv.zip to {/content}/competitions/word2vec-nlp-tutorial\n",
            " 62% 16.0M/26.0M [00:00<00:00, 69.7MB/s]\n",
            "100% 26.0M/26.0M [00:00<00:00, 103MB/s] \n",
            "Downloading testData.tsv.zip to {/content}/competitions/word2vec-nlp-tutorial\n",
            " 40% 5.00M/12.6M [00:00<00:00, 29.5MB/s]\n",
            "100% 12.6M/12.6M [00:00<00:00, 50.1MB/s]\n",
            "Downloading labeledTrainData.tsv.zip to {/content}/competitions/word2vec-nlp-tutorial\n",
            " 39% 5.00M/13.0M [00:00<00:00, 35.1MB/s]\n",
            "100% 13.0M/13.0M [00:00<00:00, 63.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bgfc-JCg4OWy",
        "colab_type": "code",
        "outputId": "425948b5-f1e0-41a8-ad47-d346c5cafbc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "!ls {/content}/competitions/word2vec-nlp-tutorial"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labeledTrainData.tsv.zip  testData.tsv.zip\n",
            "sampleSubmission.csv\t  unlabeledTrainData.tsv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yDQ6E0re4el8",
        "colab_type": "code",
        "outputId": "677c7bd8-e7a8-48c4-d734-8c3759ced0a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import  RandomForestClassifier\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "LNCPwyAu4Sp6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile('{/content}/competitions/word2vec-nlp-tutorial/labeledTrainData.tsv.zip', 'r')\n",
        "zip_ref.extractall('./')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZDG6XPRz4TiE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile('{/content}/competitions/word2vec-nlp-tutorial/testData.tsv.zip', 'r')\n",
        "zip_ref.extractall('./')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4OKOR57G4dG5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fEJ_TqQ84nAV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data=pd.read_csv('labeledTrainData.tsv',delimiter='\\t',quoting=3)\n",
        "test_data=pd.read_csv('testData.tsv',delimiter='\\t',quoting=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TdTJ0bCm4yVw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clean_text(data):\n",
        "  cleaned_text=[]\n",
        "  all_stop=stopwords.words('english')   #list of stopwords\n",
        "  ss=SnowballStemmer(\"english\")         #list of stemmer\n",
        "  for i in range(data.shape[0]):\n",
        "    soup=BeautifulSoup(data[i])            \n",
        "    html_text=soup.get_text().lower()   #for removing html tags \n",
        "    slash=re.sub('[\\\\\\\\]',\"\",html_text) # for removing backward slash\n",
        "    quotes_text=re.sub('[\\\"¨]',\" <QUOT> \",slash) # for removing double quotes\n",
        "    com=re.sub('[,]',\" <COM> \",quotes_text) # for removing comma\n",
        "    apos=re.sub(\"[']\",\" <APOS> \",com) # for removing apostrophe\n",
        "    dott=re.sub('\\.+',\" <DOT> \",apos)  # for removing full stop\n",
        "    exc=re.sub('!+',\" <EXC> \",dott)  # for removing exclamation\n",
        "    num=re.sub(\"\\d+\",\" <NUM> \",exc)  # for removing number\n",
        "    brac=re.sub('[()]+',\" <BRAC> \",num)  # for removing brackets\n",
        "    ques=re.sub(\"\\?+\",\" <QUES> \",brac)  # for removing question mark\n",
        "    split_text=ques.split()  # for splitting the text\n",
        "    stop_text=[i for i in split_text if i not in all_stop]  # for removing stopwords\n",
        "    stem_text=[ss.stem(i) for i in stop_text]  # for stemming each word\n",
        "    final_text=[i for i in stem_text if len(i)>=2]  # for removing words with length 1\n",
        "    cleaned_text.append(\" \".join(final_text)) # converting the list of cleaned words into a single sentence\n",
        "  return np.array(cleaned_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZJzF5fmM5MGM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cleaned_train_reviews=clean_text(train_data.review)\n",
        "cleaned_test_reviews=clean_text(test_data.review)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pEdT4ry_AOS2",
        "colab_type": "code",
        "outputId": "03a10ddc-3384-4f61-98f8-417e2a1e7dff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(cleaned_train_reviews.shape,cleaned_test_reviews.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000,) (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sk5NfbXS47Zm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf=TfidfVectorizer(analyzer = \"word\",tokenizer = None,preprocessor = None,stop_words = None,ngram_range=(1,3),max_features =10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FkkPjF6j49Oq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train=tf.fit_transform(cleaned_train_reviews)\n",
        "test=tf.transform(cleaned_test_reviews)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jm--8ITS5BY7",
        "colab_type": "code",
        "outputId": "51946c32-0faa-4cff-daa4-27ddb6655453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<25000x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 3400361 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "OsnC6KLV5iO5",
        "colab_type": "code",
        "outputId": "69b490d8-68c6-4b3c-c742-9fef85631d24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<25000x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 3320965 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "yWIYSIgk4_qJ",
        "colab_type": "code",
        "outputId": "2c78f116-0925-4620-95e7-35495d24c50d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(tf.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "AimFa2xT5Gs8",
        "colab_type": "code",
        "outputId": "01a10878-8d0e-48ad-f179-3a577dc46a33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "cell_type": "code",
      "source": [
        "rc=RandomForestClassifier(150)\n",
        "rc.fit(train,train_data.sentiment)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
              "            oob_score=False, random_state=None, verbose=0,\n",
              "            warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "CUZ72zoYD0Ci",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = 'drive/bag_of_words/finalized_model.sav'\n",
        "pickle.dump(rc, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "twMUQzN0EF0E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rc = pickle.load(open(filename, 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aYKoPSJO5IgD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_prediction=rc.predict(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ps-Obt495s_F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output = pd.DataFrame( data={\"id\":test_data[\"id\"], \"sentiment\":test_prediction} )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ymoM4PjkBIIM",
        "colab_type": "code",
        "outputId": "c0e82cb2-acf8-468c-ba37-2d3502a00b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "d8UjyAxYBL50",
        "colab_type": "code",
        "outputId": "c337b915-5efc-4047-96aa-757cb4bca3f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "cell_type": "code",
      "source": [
        "output.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"12311_10\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"8348_2\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"5828_4\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"7186_2\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"12128_7\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  sentiment\n",
              "0  \"12311_10\"          1\n",
              "1    \"8348_2\"          0\n",
              "2    \"5828_4\"          0\n",
              "3    \"7186_2\"          1\n",
              "4   \"12128_7\"          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "v8jviL-65v72",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output.to_csv( \"drive/Bag_of_Words_model.csv\", index=False, quoting=3 )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}